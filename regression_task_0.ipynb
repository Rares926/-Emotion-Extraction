{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/machine73/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/machine73/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import json \n",
    "import csv \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk \n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('task_0_test.csv')\n",
    "X_test, y_test = test_data[\"text\"], test_data[\"emotion\"]\n",
    "\n",
    "train_data = pd.read_csv('task_0_train.csv')\n",
    "X_train, y_train = train_data[\"text\"], train_data[\"emotion\"]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Lowercasing and removing punctuation\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "    # Removing stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "    # Convert back to string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "X_test = [preprocess_text(utterance) for utterance in X_test]\n",
    "X_train = [preprocess_text(utterance) for utterance in X_train]\n",
    "\n",
    "all_data, X_train_list = list(X_test), list(X_train)\n",
    "all_labels, X_train_labels = list(y_test), list(y_train)\n",
    "\n",
    "all_data.extend(X_train_list)\n",
    "all_labels.extend(X_train_labels)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "all_data_counts = vectorizer.fit_transform(all_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search for best solver and best penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best cross-validation score: 0.4843845778428501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.26      0.09      0.13       374\n",
      "     disgust       0.20      0.03      0.05       111\n",
      "        fear       0.50      0.02      0.04       106\n",
      "         joy       0.49      0.24      0.33       594\n",
      "     neutral       0.50      0.88      0.64      1465\n",
      "     sadness       0.42      0.16      0.23       276\n",
      "    surprise       0.54      0.28      0.37       447\n",
      "\n",
      "    accuracy                           0.49      3373\n",
      "   macro avg       0.42      0.24      0.25      3373\n",
      "weighted avg       0.46      0.49      0.42      3373\n",
      "\n",
      "Accuracy: 0.48739994070560333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
      "10 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1182, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.48438458 0.47862605 0.48057794 0.47560076        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'solver': [ 'liblinear','saga'],\n",
    "    'max_iter': [1000],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet']\n",
    "}\n",
    "\n",
    "clf = LogisticRegression()\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_counts, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate on the test set using the best found parameters\n",
    "best_clf = grid_search.best_estimator_\n",
    "y_pred = best_clf.predict(X_test_counts)\n",
    "\n",
    "# Print classification report and accuracy\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search for best reg param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.615848211066026, 'multi_class': 'ovr'}\n",
      "Best cross-validation score: 0.48789834422502354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.31      0.07      0.12       374\n",
      "     disgust       0.20      0.02      0.03       111\n",
      "        fear       0.50      0.01      0.02       106\n",
      "         joy       0.51      0.23      0.31       594\n",
      "     neutral       0.49      0.91      0.64      1465\n",
      "     sadness       0.46      0.15      0.23       276\n",
      "    surprise       0.55      0.26      0.35       447\n",
      "\n",
      "    accuracy                           0.49      3373\n",
      "   macro avg       0.43      0.24      0.24      3373\n",
      "weighted avg       0.47      0.49      0.41      3373\n",
      "\n",
      "Accuracy: 0.490364660539579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
      "100 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1212, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 99, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/machine73/anaconda3/envs/MT_P/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.12112045        nan 0.12112045        nan 0.43568222        nan\n",
      " 0.43568222        nan 0.43568222        nan 0.43568227        nan\n",
      " 0.46086243        nan 0.4739406         nan 0.47979721        nan\n",
      " 0.48789834        nan 0.4763812         nan 0.45471376        nan\n",
      " 0.43529169        nan 0.41752855        nan 0.4061103         nan\n",
      " 0.40083972        nan 0.39966837        nan 0.39830209        nan\n",
      " 0.39683805        nan 0.39635001        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'multi_class':['ovr', 'multinomial']\n",
    "}\n",
    "\n",
    "clf = LogisticRegression(penalty='l1',solver='liblinear',max_iter=1000)\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_counts, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate on the test set using the best found parameters\n",
    "best_clf = grid_search.best_estimator_\n",
    "y_pred = best_clf.predict(X_test_counts)\n",
    "\n",
    "# Print classification report and accuracy\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Results with best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.31      0.07      0.12       374\n",
      "     disgust       0.25      0.02      0.03       111\n",
      "        fear       1.00      0.01      0.02       106\n",
      "         joy       0.52      0.23      0.31       594\n",
      "     neutral       0.49      0.91      0.64      1465\n",
      "     sadness       0.45      0.15      0.22       276\n",
      "    surprise       0.55      0.26      0.35       447\n",
      "\n",
      "    accuracy                           0.49      3373\n",
      "   macro avg       0.51      0.23      0.24      3373\n",
      "weighted avg       0.49      0.49      0.41      3373\n",
      "\n",
      "Accuracy: 0.490364660539579\n",
      "Cross-validated scores: [0.49596182 0.49375918 0.49706314 0.49082232 0.48806463]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    solver='liblinear',\n",
    "    max_iter=1000,\n",
    "    C=0.6,\n",
    "    multi_class='ovr'\n",
    "    )  # 'saga' is a good choice for large datasets\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_counts)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "scores = cross_val_score(clf, all_data_counts, all_labels, cv=5)\n",
    "print(f\"Cross-validated scores: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression with saga solver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.26      0.14      0.19       374\n",
      "     disgust       0.24      0.04      0.06       111\n",
      "        fear       0.24      0.05      0.08       106\n",
      "         joy       0.45      0.27      0.34       594\n",
      "     neutral       0.53      0.81      0.64      1465\n",
      "     sadness       0.29      0.17      0.22       276\n",
      "    surprise       0.55      0.48      0.51       447\n",
      "\n",
      "    accuracy                           0.49      3373\n",
      "   macro avg       0.37      0.28      0.29      3373\n",
      "weighted avg       0.45      0.49      0.45      3373\n",
      "\n",
      "Accuracy: 0.4939223243403498\n",
      "Cross-validated scores: [0.49926579 0.49889868 0.50110132 0.49743025 0.49614396]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LogisticRegression(solver='saga', max_iter=1000)  # 'saga' is a good choice for large datasets\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_counts)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "scores = cross_val_score(clf, all_data_counts, all_labels, cv=5)\n",
    "print(f\"Cross-validated scores: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial base regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.32      0.11      0.17       374\n",
      "     disgust       0.40      0.02      0.03       111\n",
      "        fear       0.00      0.00      0.00       106\n",
      "         joy       0.50      0.23      0.31       594\n",
      "     neutral       0.49      0.91      0.64      1465\n",
      "     sadness       0.32      0.09      0.14       276\n",
      "    surprise       0.59      0.26      0.36       447\n",
      "\n",
      "    accuracy                           0.49      3373\n",
      "   macro avg       0.38      0.23      0.24      3373\n",
      "weighted avg       0.46      0.49      0.41      3373\n",
      "\n",
      "Accuracy: 0.4879928846723985\n",
      "Cross-validated scores: [0.46842878 0.48017621 0.47870778 0.47870778 0.47521116]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_counts)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "scores = cross_val_score(clf, all_data_counts, all_labels, cv=5)\n",
    "print(f\"Cross-validated scores: {scores}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MT_P",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
